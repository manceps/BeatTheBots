{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Get_Finance_Data.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tLrUdnMHvCnB",
        "colab_type": "text"
      },
      "source": [
        "# Get, prepare, and store data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f3xUaIAIu_vt",
        "colab_type": "text"
      },
      "source": [
        "### Import and functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mf4DQGBe5ww_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "37760085-9afc-44f2-a54f-bba0141bfd62"
      },
      "source": [
        "!pip install yfinance --upgrade --no-cache-dir\n",
        "!pip install tensorflow==2.0.0"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pandas-datareader in /usr/local/lib/python3.6/dist-packages (0.7.4)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.6/dist-packages (from pandas-datareader) (1.11.2)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.6/dist-packages (from pandas-datareader) (4.2.6)\n",
            "Requirement already satisfied: requests>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from pandas-datareader) (2.21.0)\n",
            "Requirement already satisfied: pandas>=0.19.2 in /usr/local/lib/python3.6/dist-packages (from pandas-datareader) (0.25.2)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.3.0->pandas-datareader) (2019.9.11)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.3.0->pandas-datareader) (2.8)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.3.0->pandas-datareader) (3.0.4)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.3.0->pandas-datareader) (1.24.3)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.19.2->pandas-datareader) (1.17.3)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.19.2->pandas-datareader) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.19.2->pandas-datareader) (2.6.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.6.1->pandas>=0.19.2->pandas-datareader) (1.12.0)\n",
            "Collecting yfinance\n",
            "  Downloading https://files.pythonhosted.org/packages/53/0e/40387099824c98be22cd7e33a620e9d38b61998b031f0b33f0b9959717d2/yfinance-0.1.45.tar.gz\n",
            "Requirement already satisfied, skipping upgrade: pandas>=0.24 in /usr/local/lib/python3.6/dist-packages (from yfinance) (0.25.2)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.15 in /usr/local/lib/python3.6/dist-packages (from yfinance) (1.17.3)\n",
            "Requirement already satisfied, skipping upgrade: requests>=2.20 in /usr/local/lib/python3.6/dist-packages (from yfinance) (2.21.0)\n",
            "Requirement already satisfied, skipping upgrade: multitasking>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from yfinance) (0.0.9)\n",
            "Requirement already satisfied, skipping upgrade: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.24->yfinance) (2018.9)\n",
            "Requirement already satisfied, skipping upgrade: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.24->yfinance) (2.6.1)\n",
            "Requirement already satisfied, skipping upgrade: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.20->yfinance) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.20->yfinance) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.20->yfinance) (2.8)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.20->yfinance) (2019.9.11)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.6.1->pandas>=0.24->yfinance) (1.12.0)\n",
            "Building wheels for collected packages: yfinance\n",
            "  Building wheel for yfinance (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for yfinance: filename=yfinance-0.1.45-cp36-none-any.whl size=14652 sha256=2e4ee08f6da43bfcc40efc57a779c2e56435bbfcea431a344229c278721b290d\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-prwptk0n/wheels/0c/d1/df/aa9a7744a4ac353cc9a1f2c3aaea7c1f457fc49de4286f2d88\n",
            "Successfully built yfinance\n",
            "Installing collected packages: yfinance\n",
            "Successfully installed yfinance-0.1.45\n",
            "Collecting tensorflow==2.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/46/0f/7bd55361168bb32796b360ad15a25de6966c9c1beb58a8e30c01c8279862/tensorflow-2.0.0-cp36-cp36m-manylinux2010_x86_64.whl (86.3MB)\n",
            "\u001b[K     |████████████████████████████████| 86.3MB 102kB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (3.10.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (1.15.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (1.11.2)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (0.8.1)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (1.17.3)\n",
            "Collecting tensorboard<2.1.0,>=2.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9b/a6/e8ffa4e2ddb216449d34cfcb825ebb38206bee5c4553d69e7bc8bc2c5d64/tensorboard-2.0.0-py3-none-any.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 28.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (3.1.0)\n",
            "Collecting tensorflow-estimator<2.1.0,>=2.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fc/08/8b927337b7019c374719145d1dceba21a8bb909b93b1ad6f8fb7d22c1ca1/tensorflow_estimator-2.0.1-py2.py3-none-any.whl (449kB)\n",
            "\u001b[K     |████████████████████████████████| 450kB 56.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (0.33.6)\n",
            "Requirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (0.2.2)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (1.1.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (0.8.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (1.0.8)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (1.1.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (0.1.7)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (1.12.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow==2.0.0) (41.4.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (0.16.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (3.1.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow==2.0.0) (2.8.0)\n",
            "Installing collected packages: tensorboard, tensorflow-estimator, tensorflow\n",
            "  Found existing installation: tensorboard 1.15.0\n",
            "    Uninstalling tensorboard-1.15.0:\n",
            "      Successfully uninstalled tensorboard-1.15.0\n",
            "  Found existing installation: tensorflow-estimator 1.15.1\n",
            "    Uninstalling tensorflow-estimator-1.15.1:\n",
            "      Successfully uninstalled tensorflow-estimator-1.15.1\n",
            "  Found existing installation: tensorflow 1.15.0\n",
            "    Uninstalling tensorflow-1.15.0:\n",
            "      Successfully uninstalled tensorflow-1.15.0\n",
            "Successfully installed tensorboard-2.0.0 tensorflow-2.0.0 tensorflow-estimator-2.0.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "efWv60t6cy40",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pandas_datareader import data\n",
        "import pandas as pd\n",
        "import yfinance as yf\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tqdm import tqdm\n",
        "import sys\n",
        "from datetime import datetime\n",
        "from google.cloud import storage\n",
        "from google.colab import auth\n",
        "yf.pdr_override()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BPK1ruiSwdQu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "auth.authenticate_user()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tBPiACkKM3tM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def _floatlist_feature(value):\n",
        "    \"\"\"Returns a float_list from a list of floats.\"\"\"\n",
        "    return tf.train.Feature(float_list=tf.train.FloatList(value=value))\n",
        "\n",
        "def _float_feature(value):\n",
        "    \"\"\"Returns a float_list from a single float.\"\"\"\n",
        "    return tf.train.Feature(float_list=tf.train.FloatList(value=[value]))\n",
        "\n",
        "def _int_feature(value):\n",
        "    \"\"\"Returns a int_list from a single int.\"\"\"\n",
        "    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n",
        "\n",
        "def upload_blob(bucket_name, source_file_name, destination_blob_name):\n",
        "    \"\"\"Uploads a file to the bucket.\"\"\"\n",
        "    storage_client = storage.Client(project = 'Adversarial-Finance')\n",
        "    bucket = storage_client.get_bucket(bucket_name)\n",
        "    blob = bucket.blob(destination_blob_name)\n",
        "    blob.upload_from_filename(source_file_name)\n",
        "    \n",
        "def scale_by_company(df, suffix, scale_func):\n",
        "    comp_df = df.unstack().unstack(level=0).reset_index(level=0, drop=False).rename(columns={'level_0':'company'}).reset_index()\n",
        "    company_stats = comp_df.groupby('company').agg(['mean','std'])\n",
        "    for feat, company in df.columns:\n",
        "        company_mean, company_std = company_stats.loc[company, feat]\n",
        "        df.loc[:,(f\"{feat}_scaled_{suffix}\", company)] = scale_func(df.loc[:, (feat, company)],\n",
        "                                                                    company_mean, company_std)\n",
        "    return df.drop(columns = [c for c in df.columns if 'scaled' not in c[0]])\n",
        "\n",
        "def scale_by_year(df, suffix, scale_func):\n",
        "    year_df = df.unstack().unstack(level=0).reset_index(level=0, drop=False).drop(columns=['level_0'])\n",
        "    yr_ix = year_df.index.to_period('Y')\n",
        "    yearly_stats = year_df.groupby(yr_ix).agg(['mean','std'])\n",
        "    yearly_stats.index = yearly_stats.index.astype(int) + 1970\n",
        "\n",
        "    df['year'] = df.index.year\n",
        "\n",
        "    for feat, company in df.columns:\n",
        "\n",
        "        if feat in ['year', 'mean', 'std']:\n",
        "            continue\n",
        "\n",
        "        df['mean'] = df.year.map(yearly_stats.loc[:,(feat, 'mean')])\n",
        "        df['std'] = df.year.map(yearly_stats.loc[:,(feat, 'std')])\n",
        "        df.loc[:,(f\"{feat}_scaled_{suffix}\", company)] = scale_func(df.loc[:, (feat, company)],\n",
        "                                                                    df['mean'], df['std'])\n",
        "    return df.drop(columns = [c for c in df.columns if 'scaled' not in c[0]])\n",
        "\n",
        "def scale_by_both(df, suffix, scale_func):\n",
        "    yr_ix = df.index.to_period('Y')\n",
        "    yearly_stats = df.groupby(yr_ix).agg(['mean','std'])\n",
        "    yearly_stats.index = yearly_stats.index.astype(int) + 1970\n",
        "\n",
        "    df['year'] = df.index.year\n",
        "\n",
        "    for feat, company in df.columns:\n",
        "\n",
        "        if feat in ['year', 'mean', 'std']:\n",
        "            continue\n",
        "\n",
        "        df['mean'] = df.year.map(yearly_stats.loc[:,(feat, company, 'mean')])\n",
        "        df['std'] = df.year.map(yearly_stats.loc[:,(feat, company, 'std')])\n",
        "        df.loc[:,(f\"{feat}_scaled_{suffix}\", company)] = scale_func(df.loc[:, (feat, company)],\n",
        "                                                                    df['mean'], df['std'])\n",
        "    return df.drop(columns = [c for c in df.columns if 'scaled' not in c[0]])\n",
        "\n",
        "def z_scale(values, m, s):\n",
        "    epsilon = sys.float_info.epsilon\n",
        "    return (values - m)/(s+epsilon)    \n",
        "\n",
        "#   recommended time series scaling for stocks through https://pdfs.semanticscholar.org/f412/4953553981e32c39273bb2745a140311d160.pdf\n",
        "# https://arxiv.org/pdf/1812.05519.pdf\n",
        "\n",
        "def tanh_scale(values, m, s):\n",
        "    epsilon = sys.float_info.epsilon\n",
        "    return 0.5 * (np.tanh(0.01 * ((values - m) / (s + epsilon))) + 1)\n",
        "\n",
        "def write_records(df, target, is_train, num_steps = 60, num_comps = len(stock_ids)):\n",
        "\n",
        "    CASES_PER_RECORD = 6000\n",
        "    source_file_name = \"temp.tfrecord\"\n",
        "    \n",
        "    assert df.shape[0] == target.shape[0]\n",
        "    \n",
        "    if is_train:\n",
        "        bucket_name = \"adversarial-finance-resources\"\n",
        "        destination_blob_name = \"data/training/train_data_{}.tfrecord\"\n",
        "    else:\n",
        "        bucket_name = \"adversarial-finance-resources\"\n",
        "        destination_blob_name = \"data/testing/test_data_{}.tfrecord\"\n",
        "    \n",
        "    cols = df.columns.get_level_values(level = 0).unique()\n",
        "    examples_written = 0\n",
        "    records_written = 0\n",
        "    df['month'] = df.index.month.astype(int)\n",
        "    df['day'] = df.index.day.astype(int)\n",
        "\n",
        "    tfwriter =  tf.io.TFRecordWriter(\"temp.tfrecord\")\n",
        "    \n",
        "    for i in tqdm(range(df.shape[0] - num_steps)):\n",
        "\n",
        "        features = {}\n",
        "        for feat in cols:\n",
        "            flat_feat_series = df.iloc[i:(i+num_steps)][feat].values.flatten()\n",
        "            features[feat] = _floatlist_feature(flat_feat_series)\n",
        "\n",
        "        features.update({'month':_int_feature(df.iloc[(i+num_steps)].month.values.astype(int)[0]),\n",
        "                     'day':_int_feature(df.iloc[(i+num_steps)].day.values.astype(int)[0]),\n",
        "                     'scaled_adj_close':_floatlist_feature(target.iloc[(i+num_steps)].values)})\n",
        "\n",
        "        example = tf.train.Example(features=tf.train.Features(feature=features))\n",
        "        tfwriter.write(example.SerializeToString())\n",
        "\n",
        "        examples_written += 1\n",
        "\n",
        "#         upload every interval and restart\n",
        "        if examples_written >= CASES_PER_RECORD:\n",
        "            tfwriter.close()\n",
        "            upload_blob(bucket_name,\n",
        "                        source_file_name,\n",
        "                        destination_blob_name.format(records_written))\n",
        "            \n",
        "            tfwriter = tf.python_io.TFRecordWriter(\"temp.tfrecord\")\n",
        "            records_written += 1\n",
        "            examples_written = 0\n",
        "\n",
        "    # upload remainded\n",
        "    if examples_written > 0:\n",
        "        tfwriter.close()\n",
        "        upload_blob(bucket_name,\n",
        "                    source_file_name,\n",
        "                    destination_blob_name.format(records_written))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y_UQmIuVu1Xc",
        "colab_type": "text"
      },
      "source": [
        "### Download and clean nulls"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ecBQSbVkc6JS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "65b7bd89-674c-4c74-bb99-683315b4f95d"
      },
      "source": [
        "# stocks:   Apple, AMD, Amazon,, Cisco, IBM, Intel, Microsoft, Nvidia'\n",
        "stock_ids = ['AAPL', 'AMD', 'AMZN', 'CSCO', 'IBM', 'INTC', 'MSFT', 'NVDA']\n",
        "df = data.get_data_yahoo(stock_ids,  datetime(1999,9,12))\n",
        "df.rename(columns={'Adj Close':\"Adj_close\"}, inplace = True)\n",
        "df.drop(columns=['Close'], inplace = True)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[*********************100%***********************]  8 of 8 downloaded\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fzSWh9A7UkXn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "outputId": "e5f053eb-5554-47e1-e057-58ab8e62e901"
      },
      "source": [
        "# day after September 11th is null.\n",
        "print(df[df.isnull().any(axis=1)])\n",
        "# drop row\n",
        "df.drop(index = df[df.isnull().any(axis=1)].index, inplace = True)\n",
        "df.isnull().sum().sum()"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "           Adj_close                         ... Volume                        \n",
            "                AAPL AMD AMZN CSCO IBM INTC  ...   AMZN CSCO IBM INTC MSFT NVDA\n",
            "Date                                         ...                               \n",
            "2001-09-12       NaN NaN  NaN  NaN NaN  NaN  ...    NaN  NaN NaN  NaN  NaN  NaN\n",
            "\n",
            "[1 rows x 40 columns]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "orTNIeG9uvog",
        "colab_type": "text"
      },
      "source": [
        "### Split data and scale"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P5ovhX6LwzVr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_df = df.loc[:\"2018-10-30\"].copy()\n",
        "train_target = train_df.pop('Adj_close')\n",
        "train_target.columns = pd.MultiIndex.from_product([['target'], train_target.columns])\n",
        "test_df = df.loc[\"2018-10-31\":].copy()\n",
        "test_target = test_df.pop('Adj_close')\n",
        "test_target.columns = pd.MultiIndex.from_product([['target'], test_target.columns])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Cxxs9bKTwwn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "scaled_train_df = pd.concat([scale_by_year(train_df.copy(), 'year', tanh_scale),\n",
        "                scale_by_both(train_df.copy(), 'company_year', tanh_scale),\n",
        "                scale_by_company(train_df.copy(), 'company', tanh_scale)], axis = 1)\n",
        "scaled_test_df = pd.concat([scale_by_year(test_df.copy(), 'year', tanh_scale),\n",
        "                scale_by_both(test_df.copy(), 'company_year', tanh_scale),\n",
        "                scale_by_company(test_df.copy(), 'company', tanh_scale)], axis = 1)\n",
        "scaled_train_target = scale_by_both(train_target.copy(), 'company_year', tanh_scale)\n",
        "scaled_test_target = scale_by_both(test_target.copy(), 'company_year', tanh_scale)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qMeaY_UMunL0",
        "colab_type": "text"
      },
      "source": [
        "### Convert to TF-Records and upload to cloud"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hM65h1SPvcRJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "69a83306-b514-476a-d5ac-1086c96645d1"
      },
      "source": [
        "write_records(scaled_train_df, scaled_train_target, is_train = True)\n",
        "write_records(scaled_test_df, scaled_test_target, is_train = False)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 4756/4756 [02:38<00:00, 29.95it/s]\n",
            "100%|██████████| 187/187 [00:06<00:00, 29.96it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0L3KqeY9wHH1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fname = 'raw_data.csv'\n",
        "df.to_csv(fname)\n",
        "upload_blob(\"adversarial-finance-resources\", fname, fname)\n",
        "dfs = ['scaled_train_df',\n",
        "        'scaled_train_target',\n",
        "        'scaled_test_df',\n",
        "        'scaled_test_target']\n",
        "\n",
        "for sub_df in dfs:\n",
        "    fname = sub_df + '.csv'\n",
        "    eval(sub_df).to_csv(fname)\n",
        "    upload_blob(\"adversarial-finance-resources\", fname, fname)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}